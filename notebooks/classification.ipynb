{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/ConvNeXt-TF/blob/main/notebooks/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "661e6538",
      "metadata": {
        "id": "661e6538"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b73e50-6538-4af5-9878-ed99489409f5",
      "metadata": {
        "id": "f2b73e50-6538-4af5-9878-ed99489409f5"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43974820-4eeb-4b3a-90b4-9ddfa00d1cb9",
      "metadata": {
        "id": "43974820-4eeb-4b3a-90b4-9ddfa00d1cb9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441b5361",
      "metadata": {
        "id": "441b5361"
      },
      "source": [
        "## Image preprocessing utilities "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e76ff1-e1e0-4c6a-91b2-4114aad60e5b",
      "metadata": {
        "id": "63e76ff1-e1e0-4c6a-91b2-4114aad60e5b"
      },
      "outputs": [],
      "source": [
        "crop_layer = keras.layers.CenterCrop(224, 224)\n",
        "norm_layer = keras.layers.Normalization(\n",
        "    mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
        "    variance=[(0.229 * 255) ** 2, (0.224 * 255) ** 2, (0.225 * 255) ** 2],\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess_image(image, size=224):\n",
        "    image = np.array(image)\n",
        "    image_resized = tf.expand_dims(image, 0)\n",
        "    \n",
        "    if size == 224:\n",
        "        image_resized = tf.image.resize(image_resized, (256, 256), method=\"bicubic\")\n",
        "        image_resized = crop_layer(image_resized)\n",
        "    elif size == 384:\n",
        "        image_resized = tf.image.resize(image, (size, size), method=\"bicubic\")\n",
        "    \n",
        "    return norm_layer(image_resized).numpy()\n",
        "    \n",
        "\n",
        "def load_image_from_url(url):\n",
        "    # Credit: Willi Gierke\n",
        "    response = requests.get(url)\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    return image, preprocessed_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b961e14",
      "metadata": {
        "id": "8b961e14"
      },
      "source": [
        "## Load ImageNet-1k labels and a demo image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc9250a-5eb6-4547-8893-dd4c746ab53b",
      "metadata": {
        "id": "8dc9250a-5eb6-4547-8893-dd4c746ab53b"
      },
      "outputs": [],
      "source": [
        "with open(\"ilsvrc2012_wordnet_lemmas.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "imagenet_int_to_str = [line.rstrip() for line in lines]\n",
        "\n",
        "img_url = \"https://p0.pikrepo.com/preview/853/907/close-up-photo-of-gray-elephant.jpg\"\n",
        "image, preprocessed_image = load_image_from_url(img_url)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9006a643",
      "metadata": {
        "id": "9006a643"
      },
      "source": [
        "## Run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dfd2c7d-e454-48da-a40b-cd5d6f6c4908",
      "metadata": {
        "id": "8dfd2c7d-e454-48da-a40b-cd5d6f6c4908"
      },
      "outputs": [],
      "source": [
        "model_url = \"https://tfhub.dev/sayakpaul/convnext_tiny_1k_224/1\"\n",
        "\n",
        "classification_model = tf.keras.Sequential(\n",
        "    [hub.KerasLayer(model_url)]\n",
        ")  \n",
        "predictions = classification_model.predict(preprocessed_image)\n",
        "predicted_label = imagenet_int_to_str[int(np.argmax(predictions))]\n",
        "print(predicted_label)"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-7.m84",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m84"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}